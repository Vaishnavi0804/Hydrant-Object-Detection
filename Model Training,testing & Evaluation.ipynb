{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4ed93f-06f0-48b4-a499-c16d867b94d8",
   "metadata": {},
   "source": [
    "\n",
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0441f6-ebd2-41be-ad10-0038dc1a49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained the model with model_main_tf2.py script present in Tensorflow Github repository\n",
    "!python /projects/rkraig/phoenix_venv/TensorFlow/models/research/object_detection/model_main_tf2.py \n",
    "--pipeline_config_path=/projects/rkraig/phoenix_venv/config_files/Efficientdet.config \n",
    "--model_dir=/projects/rkraig/phoenix_venv/Efficientdet_Training_2018\n",
    "--alsologtostderr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e80e0-c52e-4eab-bdd4-d572b8f54fe6",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beac6f0-c107-4085-b383-a4d1849e8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import cv2, time, os, tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "np.random.seed(26)\n",
    "\n",
    "\n",
    "class Detector:\n",
    "    def _init_(self):\n",
    "        pass\n",
    "    def readClasses(self, classesFilePath):\n",
    "        with open(classesFilePath, 'r') as f:\n",
    "            self.classesList = f.read().splitlines()\n",
    "        \n",
    "        #colors list\n",
    "        self.colorList = np.random.uniform(low = 0, high = 255, size = (len(self.classesList), 3))\n",
    "    \n",
    "    # Option for Download model\n",
    "    def downloadModel(self, modelURL):\n",
    "        \n",
    "        fileName = os.path.basename(modelURL)\n",
    "        self.modelName = fileName[:fileName.index('.')]\n",
    "    \n",
    "        self.cacheDir = \"/projects/rkraig/phoenix_venv/Object_detection/pretrained_models\"\n",
    "        \n",
    "        os.makedirs(self.cacheDir)\n",
    "        \n",
    "        get_file(fname = fileName, \n",
    "                origin = modelURL, cache_dir = self.cacheDir, cache_subdir = \"checkpoints\", extract = True)\n",
    "    \n",
    "    \n",
    "    # Load the downloaded model or saved model\n",
    "    def loadModel(self):\n",
    "        print(\"Loading Model \" + self.modelName)\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.model = tf.saved_model.load(os.path.join(self.cacheDir, \"checkpoints\", self.modelName, \"saved_model\"))\n",
    "        \n",
    "        print(\"Model \" + self.modelName + \"loaded successfully...\")\n",
    "        \n",
    "    def createBoundingBox(self, image, threshold = 0.5):\n",
    "        inputTensor = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        inputTesnor = tf.convert_to_tensor(inputTensor, dtype = tf.uint8)\n",
    "        inputTensor = inputTensor[tf.newaxis, ...]\n",
    "        \n",
    "        detections = self.model(inputTensor)\n",
    "        \n",
    "        bboxs = detections['detection_boxes'][0].numpy() \n",
    "        classIndexes = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "        classScores = detections['detection_scores'][0].numpy()\n",
    "        \n",
    "        \n",
    "        imH, imW, imC = image.shape\n",
    "        \n",
    "        bboxIdx = tf.image.non_max_suppression(bboxs, classScores, max_output_size= 50,\n",
    "                                              iou_threshold = threshold, score_threshold = threshold)\n",
    "        print(bboxIdx)\n",
    "        \n",
    "        if len(bboxIdx) != 0:\n",
    "            for i in bboxIdx:\n",
    "                bbox = tuple(bboxs[i].tolist())\n",
    "                classConfidence = round(100*classScores[i])\n",
    "                classIndex = classIndexes[i]\n",
    "                \n",
    "                classLabelText = self.classesList[classIndex].upper()\n",
    "                classColor = self.colorList[classIndex]\n",
    "                \n",
    "                displayText = '{}: {}%'.format(classLabelText, classConfidence)\n",
    "                \n",
    "                ymin, xmin, ymax, xmax = bbox\n",
    "                \n",
    "                xmin, xmax, ymin, ymax = (xmin * imW, xmax * imW, ymin * imH, ymax * imH)\n",
    "                xmin, xmax, ymin, ymax = int(xmin), int(xmax), int(ymin), int(ymax)\n",
    "                \n",
    "                cv2.rectangle(image, (xmin, ymin), (xmax,ymax), color = classColor, thickness = 1)\n",
    "                cv2.putText(image, displayText, (xmin, ymin - 10), cv2.FONT_HERSHEY_PLAIN, 1, classColor, 2)\n",
    "                \n",
    "                ###############################################\n",
    "                \n",
    "                lineWidth = min(int((xmax-xmin)*0.2), int ((ymax - ymin)*0.2))\n",
    "                \n",
    "                cv2.line(image, (xmin, ymin), (xmin + lineWidth, ymin), classColor, thickness = 5)\n",
    "                cv2.line(image, (xmin, ymin), (xmin, ymin + lineWidth), classColor, thickness = 5)\n",
    "                \n",
    "                cv2.line(image, (xmax, ymin), (xmax - lineWidth, ymin), classColor, thickness = 5)\n",
    "                cv2.line(image, (xmax, ymin), (xmax, ymin + lineWidth), classColor, thickness = 5)\n",
    "        \n",
    "                ###############################################\n",
    "                \n",
    "                cv2.line(image, (xmin, ymax), (xmin + lineWidth, ymax), classColor, thickness = 5)\n",
    "                cv2.line(image, (xmin, ymax), (xmin, ymax - lineWidth), classColor, thickness = 5)\n",
    "                \n",
    "                cv2.line(image, (xmax, ymax), (xmax - lineWidth, ymax), classColor, thickness = 5)\n",
    "                cv2.line(image, (xmax, ymax), (xmax, ymax - lineWidth), classColor, thickness = 5)\n",
    "                \n",
    "            return image,classConfidence,classLabelText   \n",
    "        \n",
    "        else:\n",
    "            return image, None, None\n",
    "    \n",
    "        \n",
    "    def predictImage(self, imagesPath, threshold = 0.5):\n",
    "        ImgItems = os.listdir(imagesPath)\n",
    "        # Create a dataframe to store filename, Hydrant_presence(yes/no) and confidence scores\n",
    "        df = pd.DataFrame(columns = ['Name', 'Hydrant_presence','Conf_Scores'])\n",
    "        for item in ImgItems:\n",
    "        # Open the image\n",
    "             img_path = os.path.join(imagesPath,item)\n",
    "             img = cv2.imread(img_path)\n",
    "             bboxImage,conf,lb = self.createBoundingBox(img, threshold)\n",
    "             if conf!= None:\n",
    "                    df = df.append({'Name' :item, 'Hydrant' :'YES', 'Conf_Scores' :conf},ignore_index=True)\n",
    "             else:\n",
    "                    df = df.append({'Name' :item, 'Hydrant' :'NO', 'Conf_Scores' :0},ignore_index=True)\n",
    "             #cv2.imwrite(self.modelName + \".jpg\", bboxImage)\n",
    "             path=\"/projects/rkraig/phoenix_venv/Object_detection/Output_coco_hydrant\"\n",
    "    \n",
    "             cv2.imwrite(os.path.join(path ,item), bboxImage)\n",
    "             #cv2.imwrite(os.path.join(path ,self.modelName + \"_\"+f\"{count}_.jpg\"), bboxImage)\n",
    "        \n",
    "         return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b8fd0-9659-45e2-a2cb-f1eca2796812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelURL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\"\n",
    "\n",
    "classFile = \"/projects/rkraig/phoenix_venv/Object_detection/coco_hydrant.txt\"\n",
    "imagesPath = \"/projects/rkraig/phoenix_venv/Object_detection/Evaluation/test_images\"\n",
    "threshold = 0.5\n",
    "\n",
    "detector = Detector()\n",
    "detector.readClasses(classFile)\n",
    "detector.downloadModel(modelURL)\n",
    "detector.loadModel()\n",
    "df=detector.predictImage(imagesPath, threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6bc92-a263-42fa-b189-60ea56ebc269",
   "metadata": {},
   "source": [
    "## Model Evaluation using Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147fc371-84c8-4f25-99bc-7e820728dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ground truth values\n",
    "gr_truth=pd.read_csv('/home/vadabala/Desktop/projects/rkraig/phoenix_venv/hydrant_169.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26423ff0-ba6e-43ec-a07e-159adb57ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the info about hydrant presence images\n",
    "df1=df[(df.Hydrant=='YES')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c0e74-35e2-4f92-b59c-7096d05bf466",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca229600-cbfc-4e69-91e2-d33f51607f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average confidence score of detected hydrants\n",
    "df1.Conf_Scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7541e5-212f-4136-bb0c-0016486e616c",
   "metadata": {},
   "source": [
    "#### Confusion matrix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b4a58-723c-4ea7-92fe-68e1121eece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine the false positives\n",
    "fp=0\n",
    "fp_list=[]\n",
    "for f in list(df1.Name):\n",
    "    if f not in list(gr_truth.filename):\n",
    "        fp=fp+1\n",
    "        fp_list.append(f)\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1817090-8198-4825-abcd-bca0d9f83897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine true positives\n",
    "tp=len(df1)\n",
    "not_tp_list=[]\n",
    "for f in list(df1.Name):\n",
    "    if f not in list(gr_truth.filename):\n",
    "        tp=tp-1\n",
    "        not_tp_list.append(f)\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d506f1-2b98-46bb-ab3a-84c1f0be255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine false negatives\n",
    "fn=0\n",
    "fn_list=[]\n",
    "for f in list(gr_truth.filename):\n",
    "    #print(f)\n",
    "    if f not in list(df1.Name):\n",
    "        fn+=1\n",
    "        fn_list.append(f)\n",
    "print(fn)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cb352-d67c-4df6-aa2f-838adfd565c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To determine true negatives\n",
    "tn=len(df2)\n",
    "not_tn_list=[]\n",
    "for f in list(df2.Name):\n",
    "    if f in list(gr_truth.filename):\n",
    "        tn=tn-1\n",
    "        not_tn_list.append(f)\n",
    "print(tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e46fd-8684-4783-89ae-2bdd7b95ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the precision\n",
    "precision= tp/(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e15c7-fcc2-4b4f-bd4d-fef249876858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the recall\n",
    "recall= tp/(tp+fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phoenix_venv",
   "language": "python",
   "name": "phoenix_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
